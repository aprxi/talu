{
  "name": "minilm",
  "model_types": [
    "bert",
    "minilm"
  ],
  "weight_prefixes": [
    "bert.encoder.layer.{d}.",
    "encoder.layer.{d}."
  ],
  "block": [
    {
      "op": "multihead_attention",
      "inputs": [
        {
          "tensor": "x"
        }
      ],
      "outputs": [
        "_t0"
      ],
      "qk_norm": false,
      "fused_qkv": false,
      "is_causal": false
    },
    {
      "op": "add",
      "inputs": [
        {
          "tensor": "x"
        },
        {
          "tensor": "_t0"
        }
      ],
      "outputs": [
        "_t1"
      ]
    },
    {
      "op": "norm",
      "inputs": [
        {
          "tensor": "_t1"
        }
      ],
      "outputs": [
        "_t2"
      ],
      "eps": 1e-12
    },
    {
      "op": "mlp",
      "inputs": [
        {
          "tensor": "_t2"
        }
      ],
      "outputs": [
        "_t3"
      ],
      "activation": "gelu",
      "fused_gate_up": false
    },
    {
      "op": "add",
      "inputs": [
        {
          "tensor": "_t2"
        },
        {
          "tensor": "_t3"
        }
      ],
      "outputs": [
        "_t4"
      ]
    },
    {
      "op": "norm",
      "inputs": [
        {
          "tensor": "_t4"
        }
      ],
      "outputs": [
        "_t5"
      ],
      "eps": 1e-12
    }
  ],
  "block_weights": [
    {
      "id": "self_attn.q_proj.weight",
      "module_type": "Linear",
      "layout": "linear",
      "dtype": "float32",
      "required": true,
      "candidates": [
        "bert.encoder.layer.{d}.attention.self.query.weight",
        "encoder.layer.{d}.attention.self.query.weight"
      ]
    },
    {
      "id": "self_attn.q_proj.bias",
      "module_type": "Linear",
      "layout": "linear",
      "dtype": "float32",
      "required": true,
      "candidates": [
        "bert.encoder.layer.{d}.attention.self.query.bias",
        "encoder.layer.{d}.attention.self.query.bias"
      ]
    },
    {
      "id": "self_attn.k_proj.weight",
      "module_type": "Linear",
      "layout": "linear",
      "dtype": "float32",
      "required": true,
      "candidates": [
        "bert.encoder.layer.{d}.attention.self.key.weight",
        "encoder.layer.{d}.attention.self.key.weight"
      ]
    },
    {
      "id": "self_attn.k_proj.bias",
      "module_type": "Linear",
      "layout": "linear",
      "dtype": "float32",
      "required": true,
      "candidates": [
        "bert.encoder.layer.{d}.attention.self.key.bias",
        "encoder.layer.{d}.attention.self.key.bias"
      ]
    },
    {
      "id": "self_attn.v_proj.weight",
      "module_type": "Linear",
      "layout": "linear",
      "dtype": "float32",
      "required": true,
      "candidates": [
        "bert.encoder.layer.{d}.attention.self.value.weight",
        "encoder.layer.{d}.attention.self.value.weight"
      ]
    },
    {
      "id": "self_attn.v_proj.bias",
      "module_type": "Linear",
      "layout": "linear",
      "dtype": "float32",
      "required": true,
      "candidates": [
        "bert.encoder.layer.{d}.attention.self.value.bias",
        "encoder.layer.{d}.attention.self.value.bias"
      ]
    },
    {
      "id": "self_attn.o_proj.weight",
      "module_type": "Linear",
      "layout": "linear",
      "dtype": "float32",
      "required": true,
      "candidates": [
        "bert.encoder.layer.{d}.attention.output.dense.weight",
        "encoder.layer.{d}.attention.output.dense.weight"
      ]
    },
    {
      "id": "self_attn.o_proj.bias",
      "module_type": "Linear",
      "layout": "linear",
      "dtype": "float32",
      "required": true,
      "candidates": [
        "bert.encoder.layer.{d}.attention.output.dense.bias",
        "encoder.layer.{d}.attention.output.dense.bias"
      ]
    },
    {
      "id": "input_layernorm.weight",
      "module_type": "LayerNorm",
      "layout": "none",
      "dtype": "float32",
      "required": true,
      "candidates": [
        "bert.encoder.layer.{d}.attention.output.LayerNorm.weight",
        "encoder.layer.{d}.attention.output.LayerNorm.weight"
      ]
    },
    {
      "id": "input_layernorm.bias",
      "module_type": "LayerNorm",
      "layout": "none",
      "dtype": "float32",
      "required": true,
      "candidates": [
        "bert.encoder.layer.{d}.attention.output.LayerNorm.bias",
        "encoder.layer.{d}.attention.output.LayerNorm.bias"
      ]
    },
    {
      "id": "mlp.dense_in.weight",
      "module_type": "Linear",
      "layout": "linear",
      "dtype": "float32",
      "required": true,
      "candidates": [
        "bert.encoder.layer.{d}.intermediate.dense.weight",
        "encoder.layer.{d}.intermediate.dense.weight"
      ]
    },
    {
      "id": "mlp.dense_in.bias",
      "module_type": "Linear",
      "layout": "linear",
      "dtype": "float32",
      "required": true,
      "candidates": [
        "bert.encoder.layer.{d}.intermediate.dense.bias",
        "encoder.layer.{d}.intermediate.dense.bias"
      ]
    },
    {
      "id": "mlp.dense_out.weight",
      "module_type": "Linear",
      "layout": "linear",
      "dtype": "float32",
      "required": true,
      "candidates": [
        "bert.encoder.layer.{d}.output.dense.weight",
        "encoder.layer.{d}.output.dense.weight"
      ]
    },
    {
      "id": "mlp.dense_out.bias",
      "module_type": "Linear",
      "layout": "linear",
      "dtype": "float32",
      "required": true,
      "candidates": [
        "bert.encoder.layer.{d}.output.dense.bias",
        "encoder.layer.{d}.output.dense.bias"
      ]
    },
    {
      "id": "post_attention_layernorm.weight",
      "module_type": "LayerNorm",
      "layout": "none",
      "dtype": "float32",
      "required": true,
      "candidates": [
        "bert.encoder.layer.{d}.output.LayerNorm.weight",
        "encoder.layer.{d}.output.LayerNorm.weight"
      ]
    },
    {
      "id": "post_attention_layernorm.bias",
      "module_type": "LayerNorm",
      "layout": "none",
      "dtype": "float32",
      "required": true,
      "candidates": [
        "bert.encoder.layer.{d}.output.LayerNorm.bias",
        "encoder.layer.{d}.output.LayerNorm.bias"
      ]
    }
  ],
  "pre_block": [
    {
      "op": "embedding",
      "inputs": [
        {
          "tensor": "input_ids"
        }
      ],
      "outputs": [
        "_t0"
      ],
      "name": "word_embeddings"
    },
    {
      "op": "embedding",
      "inputs": [
        {
          "tensor": "position_ids"
        }
      ],
      "outputs": [
        "_t1"
      ],
      "name": "position_embeddings"
    },
    {
      "op": "embedding",
      "inputs": [
        {
          "tensor": "token_type_ids"
        }
      ],
      "outputs": [
        "_t2"
      ],
      "name": "token_type_embeddings"
    },
    {
      "op": "add",
      "inputs": [
        {
          "tensor": "_t0"
        },
        {
          "tensor": "_t1"
        }
      ],
      "outputs": [
        "_t3"
      ]
    },
    {
      "op": "add",
      "inputs": [
        {
          "tensor": "_t3"
        },
        {
          "tensor": "_t2"
        }
      ],
      "outputs": [
        "_t4"
      ]
    },
    {
      "op": "norm",
      "inputs": [
        {
          "tensor": "_t4"
        }
      ],
      "outputs": [
        "_t5"
      ],
      "eps": 1e-12
    }
  ],
  "post_block": [],
  "global_weights": [
    {
      "id": "token_embeddings",
      "candidates": [
        "bert.embeddings.word_embeddings.weight",
        "embeddings.word_embeddings.weight"
      ],
      "module_type": "Embedding",
      "layout": "embedding",
      "dtype": "float32",
      "required": true
    },
    {
      "id": "position_embeddings",
      "candidates": [
        "bert.embeddings.position_embeddings.weight",
        "embeddings.position_embeddings.weight"
      ],
      "module_type": "Embedding",
      "layout": "embedding",
      "dtype": "float32",
      "required": true
    },
    {
      "id": "token_type_embeddings",
      "candidates": [
        "bert.embeddings.token_type_embeddings.weight",
        "embeddings.token_type_embeddings.weight"
      ],
      "module_type": "Embedding",
      "layout": "embedding",
      "dtype": "float32",
      "required": true
    },
    {
      "id": "embedding_ln",
      "candidates": [
        "bert.embeddings.LayerNorm.weight",
        "embeddings.LayerNorm.weight"
      ],
      "module_type": "LayerNorm",
      "layout": "none",
      "dtype": "float32",
      "required": true
    },
    {
      "id": "embedding_ln_bias",
      "candidates": [
        "bert.embeddings.LayerNorm.bias",
        "embeddings.LayerNorm.bias"
      ],
      "module_type": "LayerNorm",
      "layout": "none",
      "dtype": "float32",
      "required": true
    }
  ]
}
